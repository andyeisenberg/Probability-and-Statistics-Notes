<?xml version="1.0" encoding="UTF-8"?>

<chapter xml:id="ch-Probability" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Probability Theory</title>

  <introduction>
    <p>
      Text before the first section.
    </p>
  </introduction>

  <section xml:id="sec-Set-Theory" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Set Theory</title>

    <definition xml:id="def-sample-space">
      <statement>
        <p>
          The <term>sample space</term>, often denoted <m>\Omega</m>, is the set of all possible results of an experiment.
          A single result is called an <term>outcome</term>, while a collection of results is called an <term>event</term>.
        </p>
      </statement>
    </definition>

    <example>
      <statement>
        <p>
          An experiment consists of rolling a standard 6-sided die.
          The sample space is <m>\Omega = \{1, 2, 3, 4, 5, 6\}</m>.
          One possible event is <m>A = \{2, 4, 6\}</m>, i.e., the event that the result of the roll is even.
        </p>

        <p>
          What would the sample space look like if we roll the die two times and recorded the results?
        </p>
      </statement>

      <answer>
        <p>
          <md>
            <mrow> \Omega = \{\amp (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), </mrow>
            <mrow> \amp (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), </mrow>
            <mrow> \amp (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), </mrow>
            <mrow> \amp (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), </mrow>
            <mrow> \amp (5, 1), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), </mrow>
            <mrow> \amp (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)\} </mrow>
          </md>
        </p>
      </answer>
    </example>

    <definition xml:id="def-subset">
      <statement>
        <p>
          Let <m>A</m> be a set.
          The symbol <m>\in</m> means "is an element of", as in <m>a \in A</m>.
          Given another set <m>B</m>, we say <m>A</m> is a <term>subset</term> of <m>B</m>, written <m>A\subset B</m>, to mean that every element of the set <m>A</m> is also an element of the set <m>B</m>.
        </p>
      </statement>
    </definition>

    <definition xml:id="def-set-operations">
      <statement>
        <p>
          Consider sets <m>A</m> and <m>B</m>, each contained inside <m>\Omega</m>.
          We can combine sets in a variety of ways: <dl>
          <li>
            <title>Union</title>

            <p>
              The <term>union</term> of <m>A</m> and <m>B</m> is the set <m>A \cup B = \{x \mid x \in A \text{ or } x \in B\}</m>.
            </p>
          </li>

          <li>
            <title>Intersection</title>

            <p>
              The <term>intersection</term> of <m>A</m> and <m>B</m> is the set <m>A \cap B = \{x \mid x \in A \text{ and } x \in B\}</m>.
            </p>
          </li>

          <li>
            <title>Difference</title>

            <p>
              The <term>set difference</term> <m>A-B</m> is the set <m>A - B = \{x \mid x \in A \text{ and } x \notin B\}</m>.
            </p>
          </li>

          <li>
            <title>Complement</title>

            <p>
              The <term>complement</term> of <m>A</m> is the set <m>A^c = \{x \in \Omega \mid x \notin A\}</m>.
            </p>
          </li>

          <li>
            <title>Empty Set</title>

            <p>
              The <term>empty set</term>, usually written <m>\emptyset</m> or <m>\{\}</m>, is the set which contains no elements.
            </p>
          </li>
          </dl>
        </p>
      </statement>
    </definition>

    <p>
      It's useful sometimes to draw pictures representing sets...
    </p>
    <!-- TODO learn figures -->
    <definition xml:id="def-disjoint">
      <statement>
        <p>
          Two sets <m>A</m> and <m>B</m> are <term>disjoint</term> if <m>A \cap B = \emptyset</m>.
        </p>
      </statement>
    </definition>

    <definition xml:id="def-cardinality">
      <statement>
        <p>
          Given a finite set <m>A</m>, the <term>cardinality</term> of <m>A</m>, written <m>|A|</m>, is the number of elements in <m>A</m>.
        </p>
      </statement>
    </definition>

    <exercises xml:id="exercises-Set-Theory">
    <exercise>
      <introduction>
        <p>
          Consider the sets <m>A = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}</m>, <m>B = \{2, 4, 9, 10, 12, 14, 19\}</m>, and <m>C = \{9, 10, 11, 14, 16, 17, 20\}</m>, which are all subsets of <m>\Omega = \{1, 2, 3, \dotsc, 20\}</m>.
        </p>
      </introduction>


      <task>
        <statement>
          <p>
            Find <m>A - (B \cap C)</m>.
          </p>
        </statement>

        <answer>
          <p>
            <m>\{1, 2, 3, 4, 5, 6, 7, 8\}</m>
          </p>
        </answer>
      </task>


      <task>
        <statement>
          <p>
            Find <m>|A|</m>, <m>|B|</m>, <m>|C|</m>, <m>|A\cup B|</m>, <m>|A \cap B|</m>, <m>|B\cap C|</m>, <m>|A\cap C|</m>, and <m>|A\cup B\cup C|</m>.
            Is it true that the size of the union of sets is equal to the sum of the sizes of the individual sets?
          </p>
        </statement>

        <answer>
          <p>
            <m>|A| = 10</m>, <m>|B| = 7</m>, <m>|C| = 7</m>, <m>|A \cup B| = 13</m>, <m>|A \cap B| = 4</m>, <m>|B\cap C| = 3</m>, <m>|A\cap C| = 2</m>, <m>|A\cup B\cup C| = 17</m>. In particular, note that <m>|A\cup B| = 13 \neq 10 + 7 = |A| + |B|</m>, so it is not true in general that the size of the union of sets is the sum of the sizes of the individual sets.
          </p>
        </answer>
      </task>


      <task>
        <statement>
          <p>
            Find <m>A^c</m> and <m>(A\cup B)^c</m>.
          </p>
        </statement>

        <answer>
          <p>
            <m>A^c = \{11, 12, 13, 14, 15, 16, 17, 18, 19, 20\}</m>, <m>(A\cup B)^c = \{11, 13, 15, 16, 17, 18, 20\}</m>.
          </p>
        </answer>
      </task>
    </exercise>

    <exercise>
      <statement>
        <p>
          Suppose we roll a 6-sided die two times.
          List the set of all possible results.
          [Note: the result (2, 4)---rolling a 2 and then a 4---is different from the result <m>(4, 2)</m>---rolling a 4 and then a 2.]
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          Suppose we flip a coin two times.
          List the set of all possible results.
          What about flipping three times? Four times? If we flip the coin 10 times, how many possible results will there be?
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          If we roll a 6-sided die ten times, how many possible results will there be?
        </p>
      </statement>
    </exercise>
    </exercises>
  </section>

  <section xml:id="sec-Probability" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Definition of Probability</title>

    <definition xml:id="def-probability-distribution">
      <statement>
        <p>
          A <term>probability distribution</term> on a sample space <m>\Omega</m> assigns probabilities to every event, satisfying the following conditions:
          <ol>
            <li>
              <p>
                <m>\Pr(\Omega) = 1</m>.
              </p>
            </li>

            <li>
              <p>
                <m>0 \leq \Pr(A) \leq 1</m> for any event <m>A</m>.
              </p>
            </li>

            <li>
              <p>
                If <m>A \cap B = \emptyset</m>, then <m>\Pr(A\cup B) = \Pr(A) + \Pr(B)</m>.
              </p>
            </li>
          </ol>
        </p>
      </statement>
    </definition>

    <p>
      For small probability spaces (i.e., with finitely many outcomes in the sample space), we'll usually assign probabilities to each individual outcome, and perhaps list them in a table.
      Then, to find the probability of any event, simply add together the probabilities of each outcome in that event.
    </p>

    <example>
      <statement>
        <p>
          An experiment consists of rolling a standard 6-sided die.
          The sample space is <m>\Omega = \{1, 2, 3, 4, 5, 6\}</m>.
          The probability distribution (assuming a fair die) is shown below.
        </p>

        <table>
          <title>Distribution for a fair die</title>

          <tabular halign="center">
            <row bottom="minor">
              <cell><m>x</m></cell>
              <cell><m>\Pr(x)</m></cell>
            </row>

            <row>
              <cell>1</cell>
              <cell><m>1/6</m></cell>
            </row>

            <row>
              <cell>2</cell>
              <cell><m>1/6</m></cell>
            </row>

            <row>
              <cell>3</cell>
              <cell><m>1/6</m></cell>
            </row>

            <row>
              <cell>4</cell>
              <cell><m>1/6</m></cell>
            </row>

            <row>
              <cell>5</cell>
              <cell><m>1/6</m></cell>
            </row>

            <row>
              <cell>6</cell>
              <cell><m>1/6</m></cell>
            </row>
          </tabular>
        </table>

        <p>
          One possible event is <m>A = \{2, 4, 6\}</m>, i.e., the event that the result of the roll is even.
          The probability of <m>A</m> is:
          <md>
            <mrow> \Pr(A) = \Pr(2) + \Pr(4) + \Pr(6) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{3}{6} = \frac{1}{2} </mrow>
          </md>
        </p>
      </statement>
    </example>

    <definition xml:id="def-discrete-uniform">
      <statement>
        <p>
          Let <m>\Omega = \{x_1, x_2, \dotsc, x_n\}</m> be a sample space and <m>A\subset \Omega</m> an event.
          We refer to the distribution in which <m>\Pr(x_i) = \frac{1}{n}</m> for all <m>i</m> as the <term>uniform distribution</term>.
          In this case, it follows that <m>\Pr(A) = \frac{|A|}{|\Omega|}</m>.
        </p>
      </statement>
    </definition>

    <example>
      <statement>
        <p>
          A person picks a random number from 1 to 10.
          What is the probability that they picked 3?
        </p>
      </statement>
      <!-- ehhhh? -->
    </example>

    <exercises xml:id="exercises-Probability">
    <exercise>
      <statement>
        <p>
          Consider the sample space <m>\Omega = \{1, 2, 3, 4, 5, 6, 7, 8\}</m> with probability distribution below.
          Calculate the probabilities of <m>A = \{1, 3, 7, 8\}</m>, <m>B = \{2, 3, 6, 7\}</m>, <m>A\cup B</m>, and <m>A \cap B</m>.
        </p>

        <table>
          <title></title>

          <tabular halign="center">
            <row bottom="minor">
              <cell><m>x</m></cell>
              <cell><m>\Pr(x)</m></cell>
            </row>

            <row>
              <cell>1</cell>
              <cell>0.1</cell>
            </row>

            <row>
              <cell>2</cell>
              <cell>0.05</cell>
            </row>

            <row>
              <cell>3</cell>
              <cell>0.2</cell>
            </row>

            <row>
              <cell>4</cell>
              <cell>0.15</cell>
            </row>

            <row>
              <cell>5</cell>
              <cell>0.15</cell>
            </row>

            <row>
              <cell>6</cell>
              <cell>0.1</cell>
            </row>

            <row>
              <cell>7</cell>
              <cell>0.05</cell>
            </row>

            <row>
              <cell>8</cell>
              <cell>0.1</cell>
            </row>

            <row>
              <cell>9</cell>
              <cell>0.1</cell>
            </row>
          </tabular>
        </table>
        <!--</div attr= class="center">-->
      </statement>
    </exercise>

    <exercise>
      <introduction>
        <p>
          Suppose we flip a coin two times.
          Answer the questions below.
          What about three flips? What about four flips?
        </p>
      </introduction>


      <task>
        <statement>
          <p>
            Write all outcomes in the sample space <m>\Omega</m>.
          </p>
        </statement>
      </task>


      <task>
        <statement>
          <p>
            Make a probability distribution table for <m>\Omega</m> assuming the coin is fair.
          </p>
        </statement>
      </task>


      <task>
        <statement>
          <p>
            Make a probability distribution table assuming the coin comes up heads with probability 0.3.
          </p>
        </statement>
      </task>
    </exercise>

    <exercise>
      <introduction>
        <p>
          Suppose we roll a die two times.
          Answer the questions below.
        </p>
      </introduction>


      <task>
        <statement>
          <p>
            Write all outcomes in the sample space <m>\Omega</m>.
          </p>
        </statement>
      </task>


      <task>
        <statement>
          <p>
            Make a probability distribution table for <m>\Omega</m> assuming the die is fair.
          </p>
        </statement>
      </task>


      <task>
        <statement>
          <p>
            Let <m>A</m> be the event that the second roll is higher than the first, and let <m>B</m> be the event that the first roll is even.
            Find <m>\Pr(A), \Pr(B)</m>, and <m>\Pr(A \mid B)</m>.
          </p>
        </statement>
      </task>
    </exercise>

    <exercise>
      <statement>
        <p>
          Suppose a die has the values <m>1, 2, 3, 4, 5, 6</m> on the faces, but the die is not fair.
          Instead, the probabilities scale by the same amount as the face values.
          For example, a result of 4 is twice as likely as a result of 2, since 4 is twice as large as 2; a result of 6 is six times more likely than a result of 1; and so on.
          Write a probability distribution table for this die.
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          Suppose a die has the values <m>1, 2, 3, 4, 5, 6</m> on the faces, but the die is not fair.
          Instead, each even value has an equal probability, each odd value has an equal probability, and the even values are each twice as likely as the odd values to appear on a roll.
          Write a probability distribution table for this die.
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          A toxin molecule inside a cell has a 0.3 probability of leaving the cell during a 1-minute period.
          For each value of <m>n = 1, 2, 3, \dotsc</m>, find the probability of the toxin molecule leaving the cell during the <m>n</m>th minute.
          What is the probability of the molecule leaving the cell during the first 3 minutes?
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          Each of 10 toxin molecules inside a cell has a 0.3 probability of leaving the cell during a 1-minute period.
          For each value of <m>n = 1, 2, 3, \dotsc</m>, and for each value of <m>0\leq k \leq n</m>, find the probability that exactly <m>k</m> toxin molecules remain in the cell after the <m>n</m>th minute.
        </p>
      </statement>
    </exercise>
    </exercises>
  </section>

  <section xml:id="sec-Conditional-Probability" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Conditional Probability</title>

    <subsection xml:id="subsec-conditional-probability">
      <title>Conditional Probability</title>

      <definition xml:id="def-conditional-probability">
        <statement>
          <p>
            Let <m>A</m> and <m>B</m> be events.
            The <term>conditional probability</term> of <m>A</m> given <m>B</m> is
            <md>
              <mrow> \Pr(A \mid B) = \frac{\Pr(A\cap B)}{\Pr(B)}.</mrow>
            </md>
          </p>
        </statement>
      </definition>

      <example xml:id="example-rolls-conditional">
        <statement>
          <p>
            An experiment consists of rolling a fair 6-sided die two times.
            Let <m>A</m> be the event that the sum of the rolls is at least 10.
            To find <m>\Pr(A)</m>, we note that <m>A = \{(4, 6), (5, 5), (5, 6), (6, 4), (6, 5), (6, 6)\}</m>, which has 6 elements.
            Since <m>|\Omega| = 36</m>, we have
            <md>
              <mrow>\Pr(A) = \frac{|A|}{|\Omega|} = \frac{6}{36} = \frac{1}{6}</mrow>
            </md>.
          </p>

          <p>
            Let <m>B</m> be the event that the first roll is 6.
            If we pause after the first die roll seeing the value of 6, we might be more inclined to expect a sum of at least 10.
            The evidence that we've already seen changes our understanding of the situation.
            Since <m>|B| = 6</m>, <m>\Pr(B) = \frac{6}{36} = \frac{1}{6}</m>.
            Also, <m>A\cap B = \{(6, 4), (6, 5), (6, 6)\}</m>, so <m>\Pr(A\cap B) = \frac{3}{36} = \frac{1}{12}</m>.
            Finally:
            <md>
              <mrow>\Pr(A \mid B) = \frac{\Pr(A\cap B)}{\Pr(B)} = \frac{1/12}{1/6} = \frac{1}{2}</mrow>
            </md>
          </p>
        </statement>
      </example>
    </subsection>


    <subsection xml:id="subsec-diagnostic-testing">
      <title>Diagnostic Testing</title>

      <p>
        Diagnostic tests for diseases aren't perfect.
        When a test comes back positive or negative, a patient will want to understand the (conditional) probability that they have or don't have the disease based on the evidence (the diagnostic test result).
      </p>

      <definition xml:id="def-sensitivity-specificity">
        <statement>
          <p>
            The <term>sensitivity</term> of a diagnostic test is the probability that a patient who has the disease will see a positive test result.
            The <term>specificity</term> is the probability that a patient who does not have the disease will see a negative test result.
          </p>
        </statement>
      </definition>

      <p>
        Introducing event notation, let <m>D</m> be the event that a patient has the disease, and let <m>P</m> be the event that they receive a positive test result.
        Then the sensitivity of the diagnostic test is <m>\Pr(P \mid D)</m>, and the specificity is <m>\Pr(P^c \mid D^c)</m>.
        However, when the patient takes a diagnostic test, the conditional probabilities they would be most interested in would be <m>\Pr(D \mid P)</m> and <m>\Pr(D^c \mid P^c)</m>.
      </p>

      <p>
        Bayes' Theorem expresses the relationship between a conditional probability <m>\Pr(A \mid B)</m> and the flipped conditional probability <m>\Pr(B \mid A)</m>.
      </p>

      <theorem xml:id="thm-Bayes-v1">
        <title>Bayes' Theorem (v1)</title>

        <statement>
          <p>
            <md>
              <mrow> \Pr(B \mid A) = \frac{\Pr(A \mid B)\Pr(B)}{\Pr(A)} </mrow>
            </md>
          </p>
        </statement>
      </theorem>

      <p>
        For example, if a patient sees a positive diagnostic test result, they might try to calculate:
        <md>
          <mrow> \Pr(D \mid P) = \frac{\Pr(P \mid D)\Pr(D)}{\Pr(P)} </mrow>
        </md>
        It will take some work to be able to use this formula.
        We likely don't have direct access to <m>\Pr(P)</m> or <m>\Pr(D)</m>.
      </p>

      <p>
        Let's consider <m>\Pr(P)</m>, the probability of receiving a positive test result.
        The sensitivity <m>\Pr(P \mid D)</m> tells us this probability under the condition that the patient has the disease.
        For a patient who doesn't have the disease, the specificity isn't quite the number we're looking for.
        However, consider the complementary probability:
        <md>
          <mrow> \Pr(P \mid D^c) = 1 - \Pr(P^c \mid D^c) </mrow>
        </md>
        The total <m>\Pr(P)</m> can be divided into two categories: patients who have the disease and test positive, and patients who don't have the disease and test positive.
        So:
        <md number="yes">
          <mrow> \Pr(P) \amp = \Pr(P\cap D) + \Pr(P\cap D^c) </mrow>
          <mrow> \amp = \Pr(P\mid D)\Pr(D) + \Pr(P \mid D^c)\Pr(D^c) </mrow>
          <mrow> \amp = \Pr(P\mid D)\Pr(D) + (1 - \Pr(P^c \mid D^c))\Pr(D^c) </mrow>
          <mrow> \amp = (\text{sensitivity})\Pr(D) + (1 - \text{ specificity})\Pr(D^c) </mrow>
        </md>
        We can take this breakdown of <m>\Pr(P)</m> and write a new version of Bayes' Theorem:
      </p>

      <theorem xml:id="thm-Bayes-v2">
        <title>Bayes' Theorem (v2)</title>

        <statement>
          <p>
            <md>
              <mrow> \Pr(B \mid A) = \frac{\Pr(A \mid B)\Pr(B)}{\Pr(A \mid B)\Pr(B) + (1 - \Pr(A^c \mid B^c))\Pr(B^c)} </mrow>
            </md>
          </p>
        </statement>
      </theorem>

      <p>
        We're still missing a crucial piece of information: <m>\Pr(D)</m>, the probability (not conditioned on any evidence) that the patient has the disease.
        This is often referred to as the <term>prior</term>, as in, our prior understanding of the probability of something before we gained some new information from evidence.
        The conditional probability calculated using Bayes' Theorem is usually called the <term>posterior</term> (i.e., after taking evidence into account).
        There isn't always one single number that's reasonable to use as the prior probability.
        For example, in a diagnostic testing situation, the <term>prevalence</term> of the disease<mdash/>i.e., the proportion of the population who have the disease<mdash/>might feel like a natural number to use as the prior.
        However, what prevalence should you use? During the COVID-19 pandemic, the prevalence of COVID in a particular country, state, and city might be different.
        There's also the possibility of applying Bayes' Theorem multiple times to take into account multiple pieces of evidence, using the posterior probability from one application of Bayes' Theorem to play the role of the prior probability in the next.
        This idea would apply if, for example, a patient took a second diagnostic test to double-check.
      </p>

      <example>
        <statement>
          <p>
            A 50-year old woman with no symptoms is screened for breast cancer and tests positive.
            If the prevalence of breast cancer for women in her age group is 1% and the particular screening process used has a sensitivity of 90% and a specificity of 91%, what is the probability that the woman has breast cancer given her positive result?
          </p>
        </statement>

        <solution>
          <p>
            Let <m>P</m> be the event of testing positive and <m>D</m> the event of having the disease.
            Then the prevalence <m>\Pr(D)</m> is given as 1%, or 0.01.
            The sensitivity is <m>\Pr(P\mid D) = 0.9</m>, and the specificity is <m>\Pr(P^c\mid D^c) = 0.91</m>.
            So, according to Bayes' Theorem:
            <md>
              <mrow> \Pr(D\mid P) \amp = \frac{\Pr(P\mid D)\Pr(D)}{\Pr(P\mid D)\Pr(D) + (1 - \Pr(P^c\mid D^c))\Pr(D^c)} </mrow>
              <mrow>  \amp = \frac{(0.9)(0.01)}{(0.9)(0.01) + (1 - 0.91)(1 - 0.01)} </mrow>
              <mrow>  \amp \approx 0.092 </mrow>
            </md>
          </p>
        </solution>
      </example>
    </subsection>

    <exercises xml:id="exercises-Conditional-Probability"> <exercisegroup>
    <introduction>
      <p>
        In each of the following scenarios with given events <m>A</m> and <m>B</m>, alculate <m>\Pr(A), \Pr(B)</m>, <m>\Pr(A\cap B)</m>, <m>\Pr(A \mid B)</m>, and <m>\Pr(B \mid A)</m>.
      </p>
    </introduction>

    <exercise>
      <statement>
        <p>
          An experiment consists of rolling a fair die two times.
          Let <m>A</m> be the event that the sum is even, and let <m>B</m> be the event that the second roll is higher than the first.
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          An experiment consists of flipping a fair coin three times.
          Let <m>A</m> be the event that the first and second flips match.
          Let <m>B</m> be the event that there are at least two heads.
        </p>
      </statement>
    </exercise>
    </exercisegroup>

    <exercise>
      <introduction>
        <p>
          A diagnostic test is developed to detect a disease present in 3.2% of the population.
          For a patient who has the disease, the test will accurately give a positive result 65% of the time.
          When the patient does not have the disease, the test will accurately give a negative result 99.9% of the time.
        </p>
      </introduction>


      <task>
        <statement>
          <p>
            For a patient who receives a positive test, what is the probability they have the disease?
          </p>
        </statement>

        <answer>
          <p>
            TODO
          </p>
        </answer>
      </task>


      <task>
        <statement>
          <p>
            For a patient who receives a negative test, what is the probability they do not have the disease?
          </p>
        </statement>

        <answer>
          <p>
            TODO
          </p>
        </answer>
      </task>
    </exercise>
    </exercises>
  </section>

  <section xml:id="sec-Independent-Events" xmlns:xi="http://www.w3.org/2001/XInclude">
    <title>Independent Events</title>

    <p>
      The idea of conditional probability is that knowledge of one event can change our understanding of the probability of another.
      But it's also important to understand when this is not the case.
    </p>

    <definition xml:id="def-independent-events">
      <statement>
        <p>
          Events <m>A, B</m> are <term>independent</term> if <m>\Pr(A \mid B) = \Pr(A)</m>.
        </p>
      </statement>
    </definition>

    <p>
      The equation <m>\Pr(A\mid B) = \Pr(A)</m> very concretely says: knowledge that the event <m>B</m> has occurred does not change our understanding of <m>\Pr(A)</m>.
      Assuming <m>\Pr(A) \neq 0</m>, this is equivalent to <m>\Pr(A\cap B) = \Pr(A)\Pr(B)</m>, since:
      <md>
        <mrow> \Pr(A\mid B) \amp = \Pr(A) </mrow>
        <mrow> \frac{\Pr(A\cap B)}{\Pr(B)} \amp = \Pr(A) </mrow>
        <mrow> \Pr(A\cap B) \amp = \Pr(A)\Pr(B) </mrow>
      </md>
      This latter form of the equation is often more useful in calculations.
    </p>

    <example xml:id="example-rolls-independent">
      <statement>
        <p>
          In <xref ref="example-rolls-conditional"/>, we considered an experiment in which we rolled a fair 6-sided die twice.
          We defined events <m>A</m> that the sum of the rolls is at least 10 and <m>B</m> that the first roll is a 6, and we found that <m>\Pr(A \mid B) \neq \Pr(A)</m>, so <m>A</m> and <m>B</m> are not independent.
        </p>

        <p>
          Now consider the event <m>C</m> that the sum of the rolls is 7, which sounds very similar to the event <m>A</m>.
          We have:
          <md>
            <mrow> C \amp = \{(1, 6), (2, 5), (3, 4), (4, 3), (5, 2), (6, 1)\} </mrow>
            <mrow> \Pr(C) \amp = \frac{6}{36} = \frac{1}{6} </mrow>
            <mrow> B\cap C \amp = \{(6, 1)\} </mrow>
            <mrow> \Pr(B\cap C) \amp = \frac{1}{36} </mrow>
            <mrow> \text{therefore: } \Pr(C\mid B) \amp = \frac{\Pr(C\cap B)}{\Pr(B)} = \frac{1/36}{1/6} = \frac{1}{6} = \Pr(C) </mrow>
          </md>
          So, even though the descriptions of events <m>A</m> and <m>C</m> are very similar, the event <m>C</m> is independent with <m>B</m>, while <m>A</m> is not.
        </p>
      </statement>
    </example>

    <exercises xml:id="exercises-Independent-Events">
    <exercise>
      <statement>
        <p>
          An experiment consists of rolling a fair die two times.
          Let <m>A</m> be the event that the sum is even, and let <m>B</m> be the event that the second roll is higher than the first.
          Are <m>A</m> and <m>B</m> independent?
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          An experiment consists of flipping a fair coin three times.
          Let <m>A</m> be the event that the first and second flips match.
          Let <m>B</m> be the event that there are at least two heads.
          Are <m>A</m> and <m>B</m> independent?
        </p>
      </statement>
    </exercise>

    <exercise>
      <statement>
        <p>
          Let <m>A = \{1, 2, 3\}</m> and <m>B = \{3, 4, 5\}</m> be events in the sample space <m>\Omega = \{1, 2, 3, 4, 5, 6\}</m>.
          Create a probability distribution for <m>\Omega</m> so that <m>A, B</m> are independent.
        </p>
      </statement>
    </exercise>
    </exercises>
  </section>
</chapter>